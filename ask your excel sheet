
This script lets users input a excel sheet,
and then ask questions about it. It uses Retrieval-Augmented Generation (RAG) 
powered by LangChain, Groq's LLaMA3, and HuggingFace embeddings.






from langchain.llms.base import LLM
from groq import Groq
from typing import List, Optional, Any, Mapping
from pydantic import Field
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from PyPDF2 import PdfReader
import pandas as pd


class GroqLLM(LLM):
    client: Any = Field(default_factory=lambda: Groq(api_key="groq api key"))
    model_name: str = "llama3-8b-8192" 
    system_prompt: str = "You are a helpful assistant."

    @property
    def _llm_type(self) -> str:
        return "groq"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": prompt},
            ],
            max_tokens=512,
            temperature=0.7,
            stop=stop,
        )
        return response.choices[0].message.content

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        return {"model_name": self.model_name}



def extract_excel(ex):
    reader=pd.read_excel(ex)
    text_data=reader.astype(str).apply(lambda x: '|'.join(x),axis=1).tolist()
    full_text="\n".join(text_data)
    return full_text
    
def main():
    pdf=input("inset path")
    document_text=extract_excel(pdf)
    text_splitter=CharacterTextSplitter(chunk_size=100,chunk_overlap=10)
    chunks=text_splitter.split_text(document_text)

    embeddings=HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_texts(chunks,embedding=embeddings)
    retriever=vectorstore.as_retriever()

    llm=GroqLLM()
    qna_chain=RetrievalQA.from_chain_type(llm=llm,retriever=retriever)


    while True:
        question=input("enter question")
        if question.lower==exit:
            break
        answer=qna_chain.run(question)
        print("\nANSWER : ",answer,"\n")

if __name__=="__main__":
    main()
            
